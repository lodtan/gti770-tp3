{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4412028203214940326\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3164969369\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6977104006297754605\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    " \n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # third set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "with open(\"..\\\\data\\\\data\\\\csv\\\\galaxy\\\\galaxy_label_data_set.csv\", 'rt') as csvFile:\n",
    "    reader = csv.reader(csvFile, delimiter=\",\")\n",
    "    # loop over the input images\n",
    "    for index, row in enumerate(reader):\n",
    "        if index in range(1,1000):\n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            file = \"..\\\\data\\\\data\\\\images\\\\\"+row[0]+\".jpg\"\n",
    "            image = cv2.imread(file)\n",
    "            image = cv2.resize(image, (212, 212))\n",
    "            image = img_to_array(image)\n",
    "            data.append(image)\n",
    "            label = (0 if row[1] == 'smooth' else 1)\n",
    "            labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 0.6270 - acc: 0.6345 - val_loss: 0.4703 - val_acc: 0.8440\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.5847 - acc: 0.7639 - val_loss: 0.4438 - val_acc: 0.8600\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.5217 - acc: 0.7805 - val_loss: 0.4497 - val_acc: 0.8080\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.4374 - acc: 0.8272 - val_loss: 0.3855 - val_acc: 0.9040\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3849 - acc: 0.8371 - val_loss: 0.3602 - val_acc: 0.8560\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4357 - acc: 0.8026 - val_loss: 0.4023 - val_acc: 0.8880\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3585 - acc: 0.8439 - val_loss: 0.3210 - val_acc: 0.9200\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.4514 - acc: 0.8162 - val_loss: 0.3793 - val_acc: 0.8880\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.4728 - acc: 0.8136 - val_loss: 0.4372 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3995 - acc: 0.8509 - val_loss: 0.4004 - val_acc: 0.8560\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3422 - acc: 0.8661 - val_loss: 0.3996 - val_acc: 0.8240\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 8s 274ms/step - loss: 0.3465 - acc: 0.8592 - val_loss: 0.3601 - val_acc: 0.8680\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3430 - acc: 0.8688 - val_loss: 0.3501 - val_acc: 0.9160\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3420 - acc: 0.8590 - val_loss: 0.3189 - val_acc: 0.8800\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3124 - acc: 0.8729 - val_loss: 0.2584 - val_acc: 0.9160\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3106 - acc: 0.8826 - val_loss: 0.2761 - val_acc: 0.8880\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3283 - acc: 0.8702 - val_loss: 0.2452 - val_acc: 0.9280\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.2926 - acc: 0.8812 - val_loss: 0.2703 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.2424 - acc: 0.8979 - val_loss: 0.2885 - val_acc: 0.8720\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.2906 - acc: 0.8868 - val_loss: 0.2590 - val_acc: 0.9360\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 8s 273ms/step - loss: 0.2872 - acc: 0.8867 - val_loss: 0.2097 - val_acc: 0.9320\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 8s 275ms/step - loss: 0.2341 - acc: 0.9075 - val_loss: 0.2119 - val_acc: 0.9320\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.2666 - acc: 0.8825 - val_loss: 0.2824 - val_acc: 0.8840\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.2302 - acc: 0.9102 - val_loss: 0.1928 - val_acc: 0.9200\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.2398 - acc: 0.9048 - val_loss: 0.1988 - val_acc: 0.9400\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.2382 - acc: 0.8978 - val_loss: 0.2702 - val_acc: 0.8920\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.2295 - acc: 0.9033 - val_loss: 0.1926 - val_acc: 0.9480\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.2148 - acc: 0.9115 - val_loss: 0.2498 - val_acc: 0.9120\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.2326 - acc: 0.9046 - val_loss: 0.1783 - val_acc: 0.9440\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.2115 - acc: 0.9171 - val_loss: 0.1990 - val_acc: 0.9480\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.2291 - acc: 0.9103 - val_loss: 0.2462 - val_acc: 0.9120\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.2120 - acc: 0.9295 - val_loss: 0.1777 - val_acc: 0.9440\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.1988 - acc: 0.9212 - val_loss: 0.1833 - val_acc: 0.9560\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 8s 277ms/step - loss: 0.2187 - acc: 0.9198 - val_loss: 0.1709 - val_acc: 0.9360\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.2096 - acc: 0.9089 - val_loss: 0.1931 - val_acc: 0.9320\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.2107 - acc: 0.9184 - val_loss: 0.2074 - val_acc: 0.9440\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.1895 - acc: 0.9253 - val_loss: 0.2127 - val_acc: 0.9200\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.2730 - acc: 0.8964 - val_loss: 0.2618 - val_acc: 0.8880\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.2473 - acc: 0.9090 - val_loss: 0.2324 - val_acc: 0.9040\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.1898 - acc: 0.9255 - val_loss: 0.1595 - val_acc: 0.9440\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.2010 - acc: 0.9393 - val_loss: 0.1741 - val_acc: 0.9440\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.2228 - acc: 0.9128 - val_loss: 0.1984 - val_acc: 0.9400\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.1994 - acc: 0.9172 - val_loss: 0.1737 - val_acc: 0.9520\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.1766 - acc: 0.9297 - val_loss: 0.1474 - val_acc: 0.9480\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.1763 - acc: 0.9378 - val_loss: 0.1752 - val_acc: 0.9520\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.1873 - acc: 0.9282 - val_loss: 0.1557 - val_acc: 0.9600\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.1538 - acc: 0.9446 - val_loss: 0.1579 - val_acc: 0.9600\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.1785 - acc: 0.9434 - val_loss: 0.1575 - val_acc: 0.9440\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.1343 - acc: 0.9530 - val_loss: 0.1402 - val_acc: 0.9600\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.1761 - acc: 0.9420 - val_loss: 0.1795 - val_acc: 0.9400\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-3\n",
    "BS = 25\n",
    "\n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = NetCNN.build(width=212, height=212, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"..\\\\data\\\\tp3\\\\model.hdf5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Smooth/Spiral\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Graphs\\\\3c25bs3lr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GTI770]",
   "language": "python",
   "name": "conda-env-GTI770-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12918993027440423803\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3164969369\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13480577495071071783\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import Model_CNN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    " \n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "with open(\"..\\\\data\\\\data\\\\csv\\\\galaxy\\\\galaxy_label_data_set.csv\", 'rt') as csvFile:\n",
    "    reader = csv.reader(csvFile, delimiter=\",\")\n",
    "    # loop over the input images\n",
    "    for index, row in enumerate(reader):\n",
    "        if index in range(1,1000):\n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            file = \"..\\\\data\\\\data\\\\images\\\\\"+row[0]+\".jpg\"\n",
    "            image = cv2.imread(file)\n",
    "            image = cv2.resize(image, (212, 212))\n",
    "            image = img_to_array(image)\n",
    "            data.append(image)\n",
    "            label = (0 if row[1] == 'smooth' else 1)\n",
    "            labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 17s 593ms/step - loss: 0.9991 - acc: 0.5214 - val_loss: 0.6925 - val_acc: 0.4600\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.6556 - acc: 0.6461 - val_loss: 0.5693 - val_acc: 0.7920\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.6075 - acc: 0.7335 - val_loss: 0.5179 - val_acc: 0.8320\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.5686 - acc: 0.7583 - val_loss: 0.4964 - val_acc: 0.7560\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.5227 - acc: 0.7705 - val_loss: 0.4221 - val_acc: 0.8560\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.4519 - acc: 0.8053 - val_loss: 0.4546 - val_acc: 0.8360\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.4505 - acc: 0.8040 - val_loss: 0.3828 - val_acc: 0.8680\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.4015 - acc: 0.8342 - val_loss: 0.4013 - val_acc: 0.8640\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3982 - acc: 0.8466 - val_loss: 0.3414 - val_acc: 0.8920\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.4462 - acc: 0.8218 - val_loss: 0.3865 - val_acc: 0.8600\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.4022 - acc: 0.8275 - val_loss: 0.3645 - val_acc: 0.8880\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3656 - acc: 0.8495 - val_loss: 0.3039 - val_acc: 0.8920\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3367 - acc: 0.8673 - val_loss: 0.2813 - val_acc: 0.9120\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3748 - acc: 0.8509 - val_loss: 0.4461 - val_acc: 0.7880\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3395 - acc: 0.8620 - val_loss: 0.2661 - val_acc: 0.9200\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3721 - acc: 0.8330 - val_loss: 0.3266 - val_acc: 0.8960\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3262 - acc: 0.8729 - val_loss: 0.2489 - val_acc: 0.9240\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3315 - acc: 0.8675 - val_loss: 0.2580 - val_acc: 0.9240\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3378 - acc: 0.8701 - val_loss: 0.2886 - val_acc: 0.9080\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3291 - acc: 0.8647 - val_loss: 0.2812 - val_acc: 0.9240\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 25\n",
    "\n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = NetCNN.build(width=212, height=212, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='logs/LR1e3', batch_size=batch,\n",
    "                                          histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,  callbacks=[tensorboard], verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"model.hdf5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Smooth/Spiral\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot3_dropout.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GTI770]",
   "language": "python",
   "name": "conda-env-GTI770-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
